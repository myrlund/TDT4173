\documentclass[11pt,a4paper]{article}

% For å kunne skrive norske tegn.
\usepackage[utf8]{inputenc}

\usepackage{minted}

% For å inkludere figurer.
\usepackage{graphicx}

% Ekstra matematikkfunksjoner.
\usepackage{amsmath,amssymb}

\usepackage[section]{placeins}

\usepackage{hyperref}
\hypersetup{%
  colorlinks=true, % hyperlinks will be black
  urlcolor=red,
  linkcolor=red
}

\usepackage{fancyvrb}

\newenvironment{code}
  {
    \VerbatimEnvironment
    \vskip\baselineskip\hrule
    \begin{Verbatim}[xleftmargin=7pt]%
  }
  {\end{Verbatim}\hrule\vskip\baselineskip}

% Må inkluderes for blant annet å få tilgang til kommandoen \SI (korrekte måltall med enheter)
\usepackage{siunitx}

  % Prikk som multiplikasjonstegn (i steden for kryss).
  \sisetup{exponent-product = \cdot}

  % Pluss-minus-form på usikkerhet (i steden for parentes).
  \sisetup{separate-uncertainty = true}

% For å få tilgang til finere linjer (til bruk i tabeller og slikt).
\usepackage{booktabs}

% For justering av figurtekst og tabelltekst.
\usepackage[font=small,labelfont=bf]{caption}

% Subsections A, B,
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\arabic{subsection}}

% Disse kommandoene kan gjøre det enklere for LaTeX å plassere figurer og tabeller der du ønsker.
\setcounter{totalnumber}{5}
\renewcommand{\bottomfraction}{0.95}
\renewcommand{\floatpagefraction}{0.35}

\begin{document}

  % Rapportens tittel:
  \title{Assignment 1 \\ \large{TDT4173: Machine Learning and Case-Based Reasoning}}
  \author{Jonas Myrlund}

  % Her ber vi LaTeX om å lage tittelen (til nå har vi bare sagt hva den skal inneholde):
  \maketitle

  \section{} % (fold)
  \label{sec1}

    \subsection{Give two examples of relevant machine learning problems and describe them as ``well-posed learning problems''} % (fold)
    \label{sub11}
    
      A well-posed learning problem is a problem that is expressed in terms of a task $T$, a performance measure $P$, and experience $E$.
      It is said that a program is able to learn if it improves its performance $P$ at task $T$ given experience $E$.
      
      \subsubsection{Diagnosing patients} % (fold)
      \label{ssub:diagnosing_patients}
        
        \begin{description}
          \item[Task] \hfill \\
            Determining correct diagnoses for patients, given their symptoms.
          \item[Performance measure] \hfill \\
            Percentage of correctly diagnosed patients.
          \item[Experience] \hfill \\
            Patient journals, with manual correct diagnoses. Manual feedback from medical professional.
        \end{description}
        
      % subsubsection diagnosing_patients (end)
    
      \subsubsection{Playing tic-tac-toe} % (fold)
      \label{ssub:playing_tic_tac_toe}
      
        \begin{description}
          \item[Task] \hfill \\
            Beating opponents at tic-tac-toe.
          \item[Performance measure] \hfill \\
            Percentage of games won.
          \item[Experience] \hfill \\
            Games played against itself.
        \end{description}
      
      % subsubsection playing_tic_tac_toe (end)
    
    % subsection sub11 (end)
    
    \subsection{} % (fold)
      
      \subsubsection{What is inductive bias? Why is it so important in machine learning?} % (fold)
      \label{ssub:what_is_inductive_bias_why_is_it_so_important_in_machine_learning}
        
        Inductive bias is a learning algorithm's ability to use previous experience to solve problems it hasn't explicitly faced during training.
        
        In machine learning, we use training data to calibrate our algorithms to solve a \emph{general} problem.
        Without the ability to solve previously unencountered problems, we're only solving the problem for the training data -- for which we already know the solution. That really doesn't get us anywhere interesting.
        
        Occam's razor is one example: choosing the simplest solution to a problem leads to better generalization, thereby introducing a form of inductive bias.
        
      % subsubsection what_is_inductive_bias_why_is_it_so_important_in_machine_learning (end)
      
      \subsubsection{The candidate elimination algorithm for learning in version spaces and learning of decision trees with ID3 are two different learning methods. What can you say about the inductive bias for each of them?} % (fold)
      \label{ssub:the_candidate_elimination_algorithm}
        
        We consider two aspects of inductive bias separately: representation bias and preference bias.
        
        ID3 uses preference bias only, arranging decision nodes in order of projected information gain.
        
        Candidate elimination, conversely, utilises representation bias only, and assumes that the underlying concept is part of the hypothesis space.
        
      % subsubsection the_candidate_elimination_algorithm (end)
    
    % subsection  (end)

  % section sec1 (end)
  
  \section{} % (fold)
  \label{sec2}
  
    \subsection{What would be a good target function representation for learning to play tic-tac-toe?} % (fold)
    \label{sub:what_would_be_a_good_target_function_representation_for_learning_to_play_tic_tac_toe}
    
      The target function $\hat{V}(b)$ being a linear combination of the board $b$'s feature vector of length $n$, we start off with defining it as:
    
      \begin{equation}
        \hat{V}(b) = w_0 + \sum_{i=1}^n{w_i x_i}
      \end{equation}
    
      As features, we could choose something like the following:
    
      \begin{description}
        \item[$x_1$] The number of X's occurring aligned with other X's.
        \item[$x_2$] The number of O's occurring aligned with other O's.
        \item[$x_3$] The number of squares eligible for three X's in a row.
        \item[$x_4$] The number of squares eligible for three O's in a row.
      \end{description}
    
      The weights could be set to something seemingly reasonable to begin with, then tweaked by playing a human adversary, a random playing bot, or by letting the algorithm play against itself.
    
    % subsection what_would_be_a_good_target_function_representation_for_learning_to_play_tic_tac_toe_ (end)
    
    \subsection{How would you represent the tic-tac-toe board in a programming language
of your choice?} % (fold)
    \label{sub:board_representation}
    
      I would represent the board state as a two-dimensional array, and supply some simple helper functions to access its various traits.
      
      For example in Python, I would wrap the board in a class and mix in some methods for manipulating and reasoning about it -- something along these lines (quite a few methods omitted, but it expresses the general idea):
      
      \inputminted[lastline=42,linenos=true]{python}{src/board.py}
    
    % subsection how_would_you_represent_the_tic_tac_toe_board_in_a_programming_language_of_your_choice_ (end)
    
    \subsection{How would you detect the final win, loss or draw situations?} % (fold)
    \label{sub:how_would_you_detect_the_final_win_loss_or_draw_situations}
    
      Win and loss is a simple matter of checking all alignments on the board for three of the same player symbol.
      There is a draw whenever there is no winner, and no more space on the board.
      
      Here is a sample implementation, building on the above code. (The slightly obscure \texttt{is\_winning\_combo} method finds its right in the next task.)
      
      \inputminted[firstline=44,firstnumber=44,lastline=72,linenos=true]{python}{src/board.py}
    
    % subsection how_would_you_detect_the_final_win_loss_or_draw_situations (end)
  
    \subsection{How would you calculate the features ($x_i$) you chose for your representation?} % (fold)
    \label{sub:how_would_you_calculate_the_features_x_i_you_chose_for_your_representation_}
    
      Much in the same manner as the above. I'll extract some examples.
      
      \inputminted[firstline=74,firstnumber=74,lastline=100,linenos=true]{python}{src/board.py}
    
    % subsection how_would_you_calculate_the_features_x_i_you_chose_for_your_representation_ (end)
    
    \subsection{How would you determine which move to play next for a given board position?} % (fold)
    \label{sub:how_would_you_determine_which_move_to_play_next_for_a_given_board_position_}
    
      The \texttt{valid\_plays} method returns a list of all valid plays.
      What we then would like is to play the move that leads to the most desirable board setup.
      
      We can devise a simple target function with fixed weights to show the gist of it.
      
      \inputminted[firstline=118,firstnumber=118,lastline=160,linenos=true,mathescape=true]{python}{src/board.py}
    
    % subsection how_would_you_determine_which_move_to_play_next_for_a_given_board_position_ (end)
    
    \subsection{How would you use training examples to improve your target function?} % (fold)
    \label{sub:how_would_you_use_training_examples_to_improve_your_target_function_}
    
      Starting off with an initial weight vector $w$, I would through the training examples use a refining algorithm to incrementally improve the weight vector to minimize the squared error $E$:
      
      \begin{equation}
        E \equiv \sum_{\langle b, V_{\text{train}}(b) \in \text{training examples}}{ (V_\text{train}(b) - \hat{V}(b))^2 }
      \end{equation}
      
      The weight update function itself could be as simple as that of LMS (least mean squares), performing the following update for each training example number $i$:
      
      \begin{equation}
        w_i \leftarrow w_i + \eta (V_\text{train} - \hat{V}(b)) x_i
      \end{equation}
    
    % subsection how_would_you_use_training_examples_to_improve_your_target_function_ (end)
    
    \subsection{What are the main differences between using this approach for tic-tac-toe game playing and using search approaches known from AI?} % (fold)
    
      Learning algorithms don't assume to know the value of a node up front, but rather specifies \emph{which factors are relevant} to node value.
      Furthermore, in our case, we only descend one level and try to \emph{learn how to reason} about the node in itself.
      
      The strengths of the minimax and alpha-beta pruning techniques lie in their ability to search deeply, without bringing previous experience into the mix.
    
    % subsection  (end)
  
  % section sec2 (end)
  
  \section{} % (fold)
  \label{sec3}
  
    \subsection{} % (fold)
    \label{sub3_1}
    
      \subsubsection*{Training}
    
        \begin{description}
          \item[Initial] \hfill \\
            $G: \lbrace \langle ?, ?, ?, ?, ? \rangle \rbrace$ \\
            $S: \lbrace \langle \emptyset, \emptyset, \emptyset, \emptyset, \emptyset \rangle \rbrace$
          \item[Example 1] \hfill \\
            $G: \lbrace \langle ?, ?, ?, ?, ? \rangle \rbrace$ \\
            $S: \lbrace \langle Hair, Live, False, False, Flat \rangle \rbrace$
          \item[Example 2] \hfill \\
            $G: \lbrace \langle Hair, ?, ?, ?, ? \rangle, \langle ?, Live, ?, ?, ? \rangle, \langle ?, ?, False, ?, ? \rangle, \langle ?, ?, ?, False, ? \rangle, \langle ?, ?, ?, ?, Flat \rangle \rbrace$ \\
            $S: \lbrace \langle Hair, Live, False, False, Flat \rangle \rbrace$
          \item[Example 3] \hfill \\
            $G: \lbrace \langle Hair, ?, ?, ?, ? \rangle, \langle ?, Live, ?, ?, ? \rangle, \langle ?, ?, False, ?, ? \rangle, \langle ?, ?, ?, False, ? \rangle \rbrace$ \\
            $S: \lbrace \langle Hair, Live, False, False, ? \rangle \rbrace$
        \end{description}
      
      \subsubsection*{Test classification}
      
        \begin{description}
          \item[Example 1] \hfill \\
            $\langle Hair, Live, False, False, None \rangle \rightarrow True$
          \item[Example 2] \hfill \\
            $\langle Feathers, Egg, False, True, Pointed \rangle \rightarrow \text{?}$
          \item[Example 3] \hfill \\
            $\langle Scales, Egg, True, False, Flat \rangle \rightarrow \text{?}$
        \end{description}
    
    % subsection  (end)
    
    \subsection{What can the system say about the classification of the three new examples?} % (fold)
    \label{sub:what_can_the_system_say_about_the_classification_of_the_three_new_examples}
      
      While the first test example falls within the general and specific classification boundaries, the two others do not.
      Hence, we cannot say anything about their classification.
      
    % subsection what_can_the_system_say_about_the_classification_of_the_three_new_examples_ (end)
    
    \subsection{Assume that the system can ask for another training example. Which criteria should the system use to choose the training example?} % (fold)
    
      A training example with the $Body$ feature $Scales$ would enable us to reason about test example 3 above.
      
      \begin{description}
        \item[Example 4] \hfill \\
          $\langle Scales, Egg, True, False, Pointed \rangle \rightarrow False$
      \end{description}
    
    % subsection  (end)
    
    \subsection{Is the CE algorithm well-suited for all machine learning problems?} % (fold)
    \label{sub:is_the_ce_algorithm_well_suited_for_all_machine_learning_problems_}
    
      No.
      
      The CE algorithm does not handle noisy training data well -- in fact, it doesn't handle it at all.
      One single erronous training example is all that is required to disrupt the entire classifier, no matter the size of the training set.
    
    % subsection is_the_ce_algorithm_well_suited_for_all_machine_learning_problems_ (end)
  
  % section sec3 (end)
  
  \section{} % (fold)
  \label{sec4}
  
    \subsection{What rules would you create to gradually cover the training examples given for the Mammal domain in this way?} % (fold)
    \label{sub:what_rules_would_you_create_to_gradually_cover_the_training_examples_given_for_the_mammal_domain_in_this_way}
      
      I would select the variable with the least amount of entropy, that is the variable with the least uncertainty.
      In our training data we have three equal candidates so far in $Birth$, $EatsMeat$ and $CanFly$.
      
      Choosing in this way ensures a small and general decision tree, and thereby satisfies the principle of Occam's razor.
      
      \begin{minted}[gobble=8]{python}
        if Birth == "Live":
            True
        else:
            False
      \end{minted}
      
    % subsection what_rules_would_you_create_to_gradually_cover_the_training_examples_given_for_the_mammal_domain_in_this_way (end)
    
    \subsection{Assume that three more training examples are added for the Mammal domain. How does this affect what rules you would pick to describe the Mammal concept?} % (fold)
      
      The training data is no longer consistent with the \emph{IfThen} model.
      We will need to add some branching factors where the outcome is erronous.
      
      Birth is still a good starting point, but we will need to specify that pointy-teethed animals born from eggs are also mammals.
      
      \begin{minted}[gobble=8]{python}
        if Birth == "Live":
            True
        else:
            if Birth == "Egg" and Teeth == "Pointed":
                True
            else:
                False
      \end{minted}
      
      Although the tactics of \emph{IfThen} and \emph{CE} are similar in the way they work after training, they differ in how they build their classifiers:
      CE works with general and special boundaries that are pushed towards each other, accepting examples that fall between them, while the IfThen-approach builds a decision tree considering all the training examples ``at once''.
      
    % subsection subsection_name (end)
  
  % section sec4 (end)

\end{document}















